# Домашнее задание к занятию "10.06. Инцидент-менеджмент"

|      |      |
| :--- | :--- |
| Краткое описание инцидента |В 22:52 воскресенья по всемирному координированному времени несколько сервисов на GitHub.com были затронуты сетевым разделом и последующим сбоем базы данных, что привело к несогласованной информации, представленной на веб-сайте Github и ухудшению качества обслуживания на 24 часа 11 минут.|
| Предшествующие события|Регламентные работы по замене вышедшего из строя оптического оборудования 100G |
| Причина инцидента | Серверы баз данных в центре обработки данных на восточном побережье США содержали короткий период записи, который не был реплицирован на объект на западном побережье США. Поскольку кластеры баз данных в обоих центрах обработки данных теперь содержали операции записи, отсутствовавшие в другом центре обработки данных, мы не смогли безопасно выполнить возврат основного сервера в центр обработки данных на восточном побережье США.|После потери связи между сетевым концентратором и основным центром обработки данных, согласно консенсусу Raft, во время описанного выше раздела сети Orchestrator, который был активен в нашем основном центре обработки данных, начал процесс отмены выбора руководства. Центр обработки данных на западном побережье США и узлы Orchestrator общедоступного облака на восточном побережье США смогли установить кворум и начать аварийное переключение кластеров для направления операций записи в центр обработки данных на западном побережье США. Orchestrator приступил к организации топологии кластера базы данных Западного побережья США.|
| Воздействие | Серверы баз данных в центре обработки данных на восточном побережье США содержали короткий период записи, который не был реплицирован на объект на западном побережье США. Поскольку кластеры баз данных в обоих центрах обработки данных теперь содержали операции записи, отсутствовавшие в другом центре обработки данных, мы не смогли безопасно выполнить возврат основного сервера в центр обработки данных на восточном побережье США. |
| Обнаружение | В 21 октября в 22:54 по всемирному координированному времени внутренние системы мониторинга начали генерировать предупреждения, указывающие на многочисленные сбои в наших системах. В это время несколько инженеров отвечали и работали над сортировкой входящих уведомлений. К 23:02 UTC инженеры нашей группы быстрого реагирования определили, что топологии многочисленных кластеров баз данных находятся в непредвиденном состоянии. Запрос API Orchestrator показал топологию репликации базы данных, которая включала только серверы из нашего центра обработки данных на западном побережье США. |
| Реакция | В 23:09 по всемирному координированному времени команда респондентов поместила сайт в желтый статус. В 23:11 по всемирному координированному времени присоединился координатор инцидента и через две минуты изменил статус решения на красный. В 23:11 по всемирному координированному времени из запроса состояния кластеров базы данных стало ясно, что нам нужно остановить выполнение заданий, записывающих метаданные о таких вещах, как push-уведомления. Мы сделали явный выбор частично ухудшить удобство использования сайта, приостановив доставку веб-перехватчика и сборки GitHub Pages вместо того, чтобы подвергать опасности данные, которые мы уже получили от пользователей. Другими словами, наша стратегия заключалась в том, чтобы отдавать предпочтение целостности данных, а не удобству использования сайта и времени восстановления. |
| Восстановление |  Восстановление из резервных копий, синхронизация реплики на обоих сайтах, возврат к стабильной топологии обслуживания, а затем возобновление обработки заданий в очереди. |
| Таймлайн | **- 2018 21 октября 22:52 UTC** потеря связи между сетевым концентратором и основным центром обработки данных. Orchestrator начинает аварийное переключение кластеров для направления операций записи в центр обработки данных на западном побережье США. <br> **- 2018 21 октября 22:54 UTC** мониторинг начал генерировать предупреждения, указывающие на многочисленные сбои в наших системах <br> **- 2018 21 октября 23:07 UTC** вручную заблокирован наш внутренний инструмент развертывания, чтобы предотвратить внесение каких-либо дополнительных изменений <br> **- 2018 21 октября 23:09 UTC** команда респондентов поместила сайт в желтый статус <br> **- 2018 21 октября 23:11 UTC** координатор инцидента изменил статус решения на красный <br> **- 2018 21 октября 23:13 UTC** вызваны дополнительные инженеры из группы разработки баз данных GitHub <br> **- 2018 21 октября 23:19 UTC** определение стртегии для решения проблемы <br> **- 2018 22 октября 00:05 UTC** разработка плана по устранению несоответствий данных и внедрению наших процедур аварийного переключения для MySQL. Информирование пользователей о ситуации <br> **- 2018 22 октября 00:41 UTC** начат процесс резервного копирования для всех затронутых кластеров MySQL. Поиск способов ускорить передачу и время восстановления <br> **- 2018 22 октября 06:51 UTC** несколько кластеров завершили восстановление из резервных копий в нашем центре обработки данных на восточном побережье США и начали репликацию новых данных с западного побережья <br> **- 2018 22 октября 07:46 UTC** опубликовано сообщение в блоге , чтобы предоставить больше контекста <br> **- 2018 22 октября 11:12 UTC** все первичные базы данных снова установлены на восточном побережье США.Распределение нагрузки чтения по большому пулу реплик чтения <br> **- 2018 22 октября 13:15 UTC** приближение к пиковой нагрузке трафика на GitHub.com. Время репликации уменьшается, из-за увеличенного количества реплик чтения. <br> **- 2018 22 октября 16:24 UTC** закончена синхронизация реплик. Выполнено аварийное переключение на исходную топологию <br> **- 2018 22 октября 16:45 UTC** сбалансирована возросшая нагрузка. Увеличен внутренний TTL <br> **- 2018 22 октября 23:03 UTC** все ожидающие сборки вебхуков и страниц обработаны, и подтверждена целостность и правильная работа всех систем. Статус сайта обновлен до зеленого |
| Последующие действия| **Технические инициативы.**<br><br> 1. В ходе этого анализа был выявлен ряд технических инициатив. По мере того, как мы продолжаем проводить обширный внутренний анализ после инцидента, мы рассчитываем определить еще больше работы, которую необходимо выполнить. Настройте конфигурацию Orchestrator, чтобы предотвратить продвижение основных баз данных через региональные границы. Действия Оркестратора вели себя так, как настроено, несмотря на то, что наш уровень приложений не смог поддержать это изменение топологии. Выборы лидеров в регионе, как правило, безопасны, но внезапная задержка между странами стала основным фактором, способствовавшим этому инциденту. Это было неожиданное поведение системы, учитывая, что ранее мы не видели внутреннего сетевого раздела такого масштаба.<br><br> 2. Мы ускорили переход на новый механизм отчетов о состоянии, который предоставит нам более богатый форум для обсуждения активных инцидентов более четким и понятным языком. Хотя во время инцидента многие части GitHub были доступны, мы смогли установить только зеленый, желтый и красный статус. Мы понимаем, что это не дает вам точного представления о том, что работает, а что нет, и в будущем мы будем отображать различные компоненты платформы, чтобы вы знали статус каждой службы. <br><br> 3. За несколько недель до этого инцидента мы начали общекорпоративную инженерную инициативу по поддержке обслуживания трафика GitHub из нескольких центров обработки данных в схеме «активный/активный/активный». Целью этого проекта является поддержка резервирования N+1 на уровне объекта. Цель этой работы — допустить полный отказ одного центра обработки данных без воздействия на пользователя. Это серьезное усилие, которое займет некоторое время, но мы считаем, что наличие нескольких сайтов с хорошей связью в одном регионе обеспечивает хороший набор компромиссов. Этот инцидент добавил актуальности инициативе.<br> <br> 4. Мы займем более активную позицию в проверке наших предположений. GitHub — быстрорастущая компания, и за последнее десятилетие она значительно усложнилась. По мере того, как мы продолжаем расти, становится все труднее фиксировать и передавать исторический контекст компромиссов и решений, принятых новым поколениям Хабберов.<br><br> **Организационные инициативы** <br><br> Этот инцидент изменил наше отношение к надежности сайта. Мы узнали, что более строгий операционный контроль или сокращение времени отклика не являются достаточными гарантиями надежности сайта в рамках такой сложной системы служб, как наша. Чтобы поддержать эти усилия, мы также начнем системную практику проверки сценариев сбоев, прежде чем они смогут повлиять на вас. Эта работа потребует будущих инвестиций в инструменты внедрения ошибок и хаос-инжиниринга в GitHub.|
